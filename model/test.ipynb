{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sample data:**\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Though the city does not have much this kind o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rajeshwar Mahadev Temple is about 850 years ol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  Though the city does not have much this kind o...\n",
       "1  Rajeshwar Mahadev Temple is about 850 years ol..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data.csv\"\n",
    "test_data_path = \"test.csv\"\n",
    "data_raw = pd.read_csv(data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "print(\"**Sample data:**\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adventure & Outdoors', 'Spiritual', 'Nature & Retreat', 'Isolated or Hippie', 'Heritage', 'Travel & Learn', 'Social Tourism (Volunteer & Travel)', 'Nightlife & Events', 'Shopping']\n"
     ]
    }
   ],
   "source": [
    "categories = list(data_raw.columns.values)[3:12]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-Processing\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "data = data_raw\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "test_data['Review'] = test_data['Review'].str.lower()\n",
    "test_data['Review'] = test_data['Review'].apply(cleanHtml)\n",
    "test_data['Review'] = test_data['Review'].apply(cleanPunc)\n",
    "test_data['Review'] = test_data['Review'].apply(keepAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "test_data['Review'] = test_data['Review'].apply(removeStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "test_data['Review'] = test_data['Review'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "# test and train data partitioning...\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#train, test = train_test_split(test_data, random_state=42, test_size=1.0, shuffle=True)\n",
    "original_test_data = test_data\n",
    "test = test_data\n",
    "#print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0    though citi much kind old hindu structur symbo...\n",
      "1    rajeshwar mahadev templ year old said shivalin...\n",
      "Name: Review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_text = test['Review']\n",
    "#print(\"trian\")\n",
    "#print(train)\n",
    "print(\"test\")\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pickle_in = open(\"tf_idf_vectorizer.pickle\",\"rb\")\n",
    "vectorizer = pickle.load(pickle_in)\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = vectorizer.transform(train_text)\n",
    "#print(\"train_text\")\n",
    "#print(train_text)\n",
    "#print(\"x_train\")\n",
    "#print(x_train)\n",
    "#y_train = train.drop(labels = ['Review'], axis=1)\n",
    "#print(y_train)\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['Review'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Adventure & Outdoors review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[0 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Spiritual review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[1 1]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Nature & Retreat review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[1 1]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Isolated or Hippie review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[0 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Heritage review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[1 1]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Travel & Learn review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[0 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Social Tourism (Volunteer & Travel) review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[0 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Nightlife & Events review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[0 0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Shopping review...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[0 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multiple Binary Classifications - (One Vs Rest Classifier)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from IPython.display import Markdown, display\n",
    "import pickle\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "%time\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "arrs = []\n",
    "#our_model = pickle.dumps(LogReg_pipeline)\n",
    "#LogReg_pipeline = pickle.loads(our_model)\n",
    "pickle_in = open(\"trained_model.pickle\",\"rb\")\n",
    "pipeline_array = pickle.load(pickle_in)\n",
    "#print(type(pickle.loads(pipeline_array[0])))\n",
    "#pipeline_array = trained_model.read()\n",
    "#print(str(pickle.dumps(LogReg_pipeline)))\n",
    "#print(type(LogReg_pipeline))\n",
    "for index in range(0,len(categories)):\n",
    "    printmd('**Processing {} review...**'.format(categories[index]))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    #print(\"x_train\")\n",
    "    #print(x_train)\n",
    "    #LogReg_pipeline.fit(x_train, train[category])\n",
    "    LogReg_pipeline = pickle.loads(pipeline_array[index])\n",
    "    #print(train[category])\n",
    "    # calculating test accuracy\n",
    "    #print(\"x_test\")\n",
    "    #print(x_test)\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    arrs.append(prediction)\n",
    "    print(\"Prediction: \")\n",
    "    print(prediction)\n",
    "    #print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "output_array = []\n",
    "output_array.append(['Review','Adventure & Outdoors', 'Spiritual', 'Nature & Retreat', 'Isolated or Hippie', 'Heritage', 'Travel & Learn', 'Social Tourism (Volunteer & Travel)', 'Nightlife & Events', 'Shopping'])\n",
    "test_review = original_test_data[\"Review\"].values\n",
    "for index in range(0,len(test_review)):\n",
    "    row = []\n",
    "    row.append(test_review[index])\n",
    "    for arr in arrs:\n",
    "        row.append(arr[index])\n",
    "    output_array.append(row)\n",
    "\n",
    "    \n",
    "with open('output.csv', 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows(output_array)    \n",
    "#print(output_array)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
